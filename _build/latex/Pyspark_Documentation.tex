% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}

\addto\captionsenglish{\renewcommand{\figurename}{Fig. }}
\addto\captionsenglish{\renewcommand{\tablename}{Table }}
\floatname{literal-block}{Listing }



\title{Pyspark\_Documentation Documentation}
\date{March 13, 2017}
\release{0.1}
\author{pmeu}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cpf\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@ch\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@mb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\renewcommand\PYGZsq{\textquotesingle}

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}


Contents:


\chapter{Pandas}
\label{Pandas_Documentation:pandas}\label{Pandas_Documentation:welcome-to-pyspark-documentation-s-documentation}\label{Pandas_Documentation::doc}

\section{Basic Pandas documentation}
\label{Pandas_Documentation:basic-pandas-documentation}\setbox0\vbox{
\begin{minipage}{0.95\linewidth}
\textbf{Your Topic Title}

\medskip


The objective here is to have everything useful for the projects, not to make a complete documentation of the whole package. Here I will try to document both version 1.6 and \textgreater{}2.0. A special enphase will be done on machine learning module ml (mllib is outdated).
\end{minipage}}
\begin{center}\setlength{\fboxsep}{5pt}\shadowbox{\box0}\end{center}


\subsection{Importing Pyspark modules}
\label{Pandas_Documentation:importing-pyspark-modules}
There are many different ones. among the most commonly used:

\begin{Verbatim}[commandchars=\\\{\}]
from pyspark.sql.functions import *
\end{Verbatim}


\subsection{SAVING OF PANDAS DATAFRAME -\textgreater{} LIBSVM FORMAT FILE AND INVERSE}
\label{Pandas_Documentation:saving-of-pandas-dataframe-libsvm-format-file-and-inverse}
\begin{Verbatim}[commandchars=\\\{\}]
import pandas as pd
import numpy as np
from sklearn.datasets import dump\PYGZus{}svmlight\PYGZus{}file

df = pd.DataFrame()
df[\PYGZsq{}Id\PYGZsq{}] = np.arange(10)
df[\PYGZsq{}F1\PYGZsq{}] = np.random.rand(10,)
df[\PYGZsq{}F2\PYGZsq{}] = np.random.rand(10,)
df[\PYGZsq{}Target\PYGZsq{}] = np.random.randint(2,size=10) \PYGZsh{}map(lambda x: \PYGZhy{}1 if x \PYGZlt{} 0.5 else 1, np.random.rand(10,))
X = df[np.setdiff1d(df.columns,[\PYGZsq{}Id\PYGZsq{},\PYGZsq{}Target\PYGZsq{}])]
y = df.Target
dump\PYGZus{}svmlight\PYGZus{}file(X,y,\PYGZsq{}smvlight.dat\PYGZsq{},zero\PYGZus{}based=True,multilabel=False)
\end{Verbatim}

\#Now reading a SVMLigt file into (almost) a pandas object:
from sklearn.datasets import load\_svmlight\_file
data = load\_svmlight\_file(`smvlight.dat')
XX,yy = data{[}0{]},data{[}1{]}

Note: we may also load two (or more) datasets at once: load\_svmlight\_fileS!
X\_train, y\_train, X\_test, y\_test = load\_svmlight\_files( (``/path/to/train\_dataset.txt'', ``/path/to/test\_dataset.txt'') )


\chapter{Scikit-learn}
\label{Sklearn_Documentation:scikit-learn}\label{Sklearn_Documentation::doc}

\section{Basic Scikit-learn documentation}
\label{Sklearn_Documentation:basic-scikit-learn-documentation}\setbox0\vbox{
\begin{minipage}{0.95\linewidth}
\textbf{Your Topic Title}

\medskip


The objective here is to have everything useful for the projects, not to make a complete documentation of the whole package. Here I will try to document both version 1.6 and \textgreater{}2.0. A special enphase will be done on machine learning module ml (mllib is outdated).
\end{minipage}}
\begin{center}\setlength{\fboxsep}{5pt}\shadowbox{\box0}\end{center}


\subsection{Importing Pyspark modules}
\label{Sklearn_Documentation:importing-pyspark-modules}
There are many different ones. among the most commonly used:

\begin{Verbatim}[commandchars=\\\{\}]
from pyspark.sql.functions import *
\end{Verbatim}


\chapter{Pyspark}
\label{Pyspark_Documentation:pyspark}\label{Pyspark_Documentation::doc}

\section{Basic Pyspark documentation}
\label{Pyspark_Documentation:basic-pyspark-documentation}\setbox0\vbox{
\begin{minipage}{0.95\linewidth}
\textbf{Your Topic Title}

\medskip


The objective here is to have everything useful for the projects, not to make a complete documentation of the whole package. Here I will try to document both version 1.6 and \textgreater{}2.0. A special enphase will be done on machine learning module ml (mllib is outdated).
We will not review the full Pyspark documentation. For that, look at \href{http://spark.apache.org/docs/1.6.0/programming-guide.html}{http://spark.apache.org/docs/1.6.0/programming-guide.html} for version 1.6, \href{http://spark.apache.org/docs/2.1.0/programming-guide.html}{http://spark.apache.org/docs/2.1.0/programming-guide.html} for version 2.1.
\end{minipage}}
\begin{center}\setlength{\fboxsep}{5pt}\shadowbox{\box0}\end{center}


\subsection{Importing Pyspark modules}
\label{Pyspark_Documentation:importing-pyspark-modules}
There are many different ones. among the most commonly used:

\begin{Verbatim}[commandchars=\\\{\}]
from pyspark.sql.functions import *
\end{Verbatim}


\subsection{Creation of Pyspark objects}
\label{Pyspark_Documentation:creation-of-pyspark-objects}
First we need to create a Spark context:

\begin{Verbatim}[commandchars=\\\{\}]
from pyspark import SparkContext, SparkConf
conf = SparkConf().setAppName(appName).setMaster(master)
sc = SparkContext(conf=conf)
\end{Verbatim}

If the Spark context is created to read SQL data, then we can simply use:

\begin{Verbatim}[commandchars=\\\{\}]
sql = \PYGZdq{}\PYGZdq{}\PYGZdq{}
select * from risk\PYGZus{}work.PBAFF\PYGZus{}TestTrans
\PYGZdq{}\PYGZdq{}\PYGZdq{}
\PYGZsh{} Create a cashed version of data
Data = sqlContext.sql(sql).cache()
\end{Verbatim}


\subsection{Basic commands}
\label{Pyspark_Documentation:basic-commands}
\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{}counting
p1.count()

\PYGZsh{}displaying 20 rows
p1.show(20)

Grouping and aggregating:
p4 = p3.groupBy(\PYGZdq{}KNID\PYGZdq{},\PYGZdq{}IDKT\PYGZdq{},\PYGZdq{}counter\PYGZus{}account\PYGZdq{}).agg(\PYGZob{}\PYGZdq{}BLPS\PYGZdq{}: \PYGZdq{}sum\PYGZdq{}, \PYGZdq{}KNID\PYGZdq{}: \PYGZdq{}count\PYGZdq{}\PYGZcb{})

Sorting:
p4.sort(\PYGZdq{}KNID\PYGZdq{},\PYGZdq{}sum(BLPS)\PYGZdq{},ascending=False).show(100)

Moving to a Pandas dataframe:
df = p4.toPandas()
\end{Verbatim}


\subsection{Creation of a table in Hadoop}
\label{Pyspark_Documentation:creation-of-a-table-in-hadoop}
\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{}mode: one of append, overwrite, error, ignore (default: error)
\PYGZsh{}partitionBy: names of partitioning columns
p2.saveAsTable(\PYGZsq{}risk\PYGZus{}work.TULE\PYGZus{}savetest\PYGZsq{},partitionBy=\PYGZsq{}KNID\PYGZsq{},mode=\PYGZsq{}overwrite\PYGZsq{})
\end{Verbatim}


\subsection{Filtering data in Pyspark}
\label{Pyspark_Documentation:filtering-data-in-pyspark}
\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{}example 1:
p2 = p1.filter(p1.BLPS \PYGZgt{}0)

\PYGZsh{}example 2:
p3 = p2.filter(trim(p2.KNID) == \PYGZsq{}0011106277\PYGZsq{}).cache()
\end{Verbatim}


\subsection{Opening tables from Data Warehouse and MCS}
\label{Pyspark_Documentation:opening-tables-from-data-warehouse-and-mcs}
\begin{Verbatim}[commandchars=\\\{\}]
import sys
TOOLS\PYGZus{}PATH = \PYGZsq{}/home/BC3589/Git/tools\PYGZsq{}
if TOOLS\PYGZus{}PATH not in sys.path:
  sys.path.append(TOOLS\PYGZus{}PATH)

from connection.SQLConnector import SQLConnector

\PYGZsh{} testing connection to Exploration Warehouse
etpew\PYGZus{}connector = SQLConnector(\PYGZsq{}ETPEW\PYGZsq{})
sql = \PYGZdq{}select top 1 * from [ETZ3EW].[dbo].[ZW\PYGZus{}KUNDE\PYGZus{}MST\PYGZus{}HV];\PYGZdq{}
df = etpew\PYGZus{}connector.query\PYGZus{}to\PYGZus{}pandas(sql)
print(\PYGZsq{}Loaded from [ETZ3EW].[dbo].[ZW\PYGZus{}KUNDE\PYGZus{}MST\PYGZus{}HV]\PYGZsq{})
print(df.iloc[0])

\PYGZsh{} testing connection to MCS
mcs\PYGZus{}connector = SQLConnector(\PYGZsq{}MCS\PYGZsq{})
sql = \PYGZdq{}SELECT top 1 * FROM sys.databases\PYGZdq{}
df = mcs\PYGZus{}connector.query\PYGZus{}to\PYGZus{}pandas(sql)
print(\PYGZsq{}Loaded from sys.databases\PYGZsq{})
print(df.iloc[0])
\end{Verbatim}


\section{Popular algorithms using Pyspark}
\label{Pyspark_Documentation:popular-algorithms-using-pyspark}
For the machine-learning package, look at:
* Version 1.6: \href{https://spark.apache.org/docs/1.6.0/ml-guide.html}{https://spark.apache.org/docs/1.6.0/ml-guide.html}
* Version 2.1: \href{https://spark.apache.org/docs/2.1.0/ml-guide.html}{https://spark.apache.org/docs/2.1.0/ml-guide.html}

The distinction is very important! After version 2.0, RDDs are deprecated (removed in Spark 3.0) in profit of Pyspark dataframes, which are much more Pandas-friendly.


\subsection{Kernel Density Estimation (here 1-D only)}
\label{Pyspark_Documentation:kernel-density-estimation-here-1-d-only}
Here we still use the old mllib package. Look for the same using the ml one.

\begin{Verbatim}[commandchars=\\\{\}]
from pyspark.mllib.stat import KernelDensity
from pyspark.mllib.random import RandomRDDs
\PYGZpc{}matplotlib inline

\PYGZsh{} Create the estimator
kd = KernelDensity()
\PYGZsh{} Choose the range to evaluate density on
ran=np.arange(\PYGZhy{}100,100,0.1);
\PYGZsh{} Set kernel bandwidth
kd.setBandwidth(3.0)

\PYGZsh{}Here with a random normal sample
u = RandomRDDs.normalRDD(sc, 10000, 10)
kd.setSample(u)
\PYGZsh{}plot of the histogram
num\PYGZus{}bins = 50
n, bins, patches = plt.hist(u.collect(), num\PYGZus{}bins, normed=1)
\PYGZsh{}plot of the kde
densities = kd.estimate(ran)
plt.plot(ran,densities)

\PYGZsh{}Here with a true variable: the age (takes some time to compile)
sql = \PYGZdq{}\PYGZdq{}\PYGZdq{}
select * from risk\PYGZus{}temp.TULE\PYGZus{}TP5
\PYGZdq{}\PYGZdq{}\PYGZdq{}
p1 = sqlContext.sql(sql)
p2 = p1.filter(p1.statusondate == \PYGZsq{}2014\PYGZhy{}01\PYGZhy{}01\PYGZsq{}).cache()
p\PYGZus{}age = p2.map(lambda y: y[\PYGZsq{}ac\PYGZus{}age\PYGZus{}cust\PYGZus{}01\PYGZsq{}])
kd.setSample(p\PYGZus{}age)
\PYGZsh{} Choose the range to evaluate density on
ran=np.arange(0,100,0.1);  \PYGZsh{}We evaluate the KDE in the age range [0,100]
densities = kd.estimate(ran)
plt.plot(ran,densities);
\end{Verbatim}


\subsection{Subject Subtitle}
\label{Pyspark_Documentation:subject-subtitle}
Subtitles are set with `-` and are required to have the same length
of the subtitle itself, just like titles.

Lists can be unnumbered like:
\begin{itemize}
\item {} 
Item Foo

\item {} 
Item Bar

\end{itemize}

Or automatically numbered:
\begin{enumerate}
\item {} 
Item 1

\item {} 
Item 2

\end{enumerate}


\subsection{Inline Markup}
\label{Pyspark_Documentation:inline-markup}
Words can have \emph{emphasis in italics} or be \textbf{bold} and you can define
code samples with back quotes, like when you talk about a command: \code{sudo}
gives you super user powers!

HERE:
\begin{itemize}
\item {} 
\href{http://matplotlib.org/sampledoc/extensions.html\#ipython-sessions}{http://matplotlib.org/sampledoc/extensions.html\#ipython-sessions}

\item {} 
\href{http://matplotlib.org/sampledoc/extensions.html\#using-math}{http://matplotlib.org/sampledoc/extensions.html\#using-math}

\end{itemize}

The {\hyperref[Pyspark_Documentation:enumerate]{\emph{\code{enumerate()}}}} function can be used for ...
\index{enumerate() (built-in function)}

\begin{fulllineitems}
\phantomsection\label{Pyspark_Documentation:enumerate}\pysiglinewithargsret{\bfcode{enumerate}}{\emph{sequence}\optional{, \emph{start=0}}}{}
Return an iterator that yields tuples of an index and an item of the
\emph{sequence}. (And so on.)

\end{fulllineitems}


intersphinx\_mapping = \{`python': (`\href{https://docs.python.org/3}{https://docs.python.org/3}`, None)\}

\begin{Verbatim}[commandchars=\\\{\}]
In [69]: lines = plot([1,2,3])

In [70]: setp(lines)
  alpha: float
  animated: [True \textbar{} False]
  antialiased or aa: [True \textbar{} False]
  ...snip
\end{Verbatim}

\begin{tabulary}{\linewidth}{|L|L|L|}
\hline
 \multicolumn{2}{|l|}{\textsf{\relax 
Inputs
}} & \textsf{\relax 
Output
}\\
\hline\textsf{\relax 
A
} & \textsf{\relax 
B
} & \textsf{\relax 
A or B
}\\
\hline
False
 & 
False
 & 
False
\\
\hline
True
 & 
False
 & 
True
\\
\hline\end{tabulary}


\begin{Verbatim}[commandchars=\\\{\}]
\PYGZgt{}\PYGZgt{}\PYGZgt{} from pyspark.mllib.linalg import Vectors
\PYGZgt{}\PYGZgt{}\PYGZgt{} df = sqlContext.createDataFrame([(Vectors.dense([0.0]),), (Vectors.dense([2.0]),)], [\PYGZdq{}a\PYGZdq{}])
\PYGZgt{}\PYGZgt{}\PYGZgt{} standardScaler = StandardScaler(inputCol=\PYGZdq{}a\PYGZdq{}, outputCol=\PYGZdq{}scaled\PYGZdq{})
\PYGZgt{}\PYGZgt{}\PYGZgt{} model = standardScaler.fit(df)
\PYGZgt{}\PYGZgt{}\PYGZgt{} model.mean
DenseVector([1.0])
\PYGZgt{}\PYGZgt{}\PYGZgt{} model.std
DenseVector([1.4142])
\PYGZgt{}\PYGZgt{}\PYGZgt{} model.transform(df).collect()[1].scaled
DenseVector([1.4142])
\end{Verbatim}
\begin{gather}
\begin{split}W^{3\beta}_{\delta_1 \rho_1 \sigma_2} \approx U^{3\beta}_{\delta_1 \rho_1}\end{split}\notag
\end{gather}\setbox0\vbox{
\begin{minipage}{0.95\linewidth}
\textbf{Sidebar Title
     :subtitle: Optional Sidebar Subtitle}

\medskip


Subsequent indented lines comprise
the body of the sidebar, and are
interpreted as body elements.
\end{minipage}}
\begin{center}\setlength{\fboxsep}{5pt}\shadowbox{\box0}\end{center}


\chapter{Indices and tables}
\label{index:indices-and-tables}\begin{itemize}
\item {} 
\DUspan{xref,std,std-ref}{genindex}

\item {} 
\DUspan{xref,std,std-ref}{modindex}

\item {} 
\DUspan{xref,std,std-ref}{search}

\end{itemize}



\renewcommand{\indexname}{Index}
\printindex
\end{document}
