

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Pyspark &mdash; Pyspark_Documentation 0.1 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="Pyspark_Documentation 0.1 documentation" href="index.html"/>
        <link rel="next" title="Text Mining in Python" href="Text_Mining_Documentation.html"/>
        <link rel="prev" title="Scikit-learn" href="Sklearn_Documentation.html"/>
    <link href="_static/style.css" rel="stylesheet" type="text/css">


  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Pyspark_Documentation
          

          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Pandas_Documentation.html">Python, Jupyter and Pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sklearn_Documentation.html">Scikit-learn</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Pyspark</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#basic-pyspark-documentation">Basic Pyspark documentation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#importing-pyspark-modules">Importing Pyspark modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="#creation-of-pyspark-objects">Creation of Pyspark objects</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rdds">RDDs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dataframes">Dataframes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#basic-commands">Basic commands</a></li>
<li class="toctree-l3"><a class="reference internal" href="#aggregating-in-pyspark">Aggregating in Pyspark</a></li>
<li class="toctree-l3"><a class="reference internal" href="#joins">Joins</a></li>
<li class="toctree-l3"><a class="reference internal" href="#window-functions">Window functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#converting-dates-in-pyspark">Converting dates in Pyspark</a></li>
<li class="toctree-l3"><a class="reference internal" href="#nan-null-none-handling">NaN/Null/None handling</a></li>
<li class="toctree-l3"><a class="reference internal" href="#saving-a-table-in-hadoop">Saving a table in Hadoop</a></li>
<li class="toctree-l3"><a class="reference internal" href="#filtering-data-in-pyspark">Filtering data in Pyspark</a></li>
<li class="toctree-l3"><a class="reference internal" href="#opening-tables-from-data-warehouse-and-mcs">Opening tables from Data Warehouse and MCS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#user-defined-functions-udf">User-defined functions (UDF)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#machine-learning-using-the-mllib-package">Machine Learning using the MLlib package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#the-random-forest">The Random Forest</a></li>
<li class="toctree-l3"><a class="reference internal" href="#kernel-density-estimation-here-1-d-only">Kernel Density Estimation (here 1-D only)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#machine-learning-using-the-ml-package">Machine Learning using the ML package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#convert-a-string-column-to-indexed-labels">Convert a string column to indexed labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="#assembling-multiple-columns-in-one-features-columns-using-vectorassembler">Assembling multiple columns in one “features” columns using VectorAssembler</a></li>
<li class="toctree-l3"><a class="reference internal" href="#one-hot-encoding">One-Hot encoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="#grouping-data-using-bucketizer">Grouping data using Bucketizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id1">The Random Forest</a></li>
<li class="toctree-l3"><a class="reference internal" href="#evaluation-of-accuracy">Evaluation of accuracy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#text-analysis-in-pyspark">Text analysis in Pyspark</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#dealing-with-text-tokenizer-hashing-idf">Dealing with text: Tokenizer, Hashing, IDF</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Text_Mining_Documentation.html">Text Mining in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="DeepLearning_Documentation.html">Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Time_Series_inPython_Documentation.html">Time Series in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="Algorithms_Documentation.html">Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="SQL_Documentation.html">SQL Server documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Bash_Documentation.html">Useful Bash commands</a></li>
<li class="toctree-l1"><a class="reference internal" href="Bash_Documentation.html#useful-git-commands">Useful GIT commands</a></li>
<li class="toctree-l1"><a class="reference internal" href="Bash_Documentation.html#useful-vim-commands">Useful VIM commands</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sphinx_stuff.html">Sphinx</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">Pyspark_Documentation</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Pyspark</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/Pyspark_Documentation.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="pyspark">
<h1>Pyspark<a class="headerlink" href="#pyspark" title="Permalink to this headline">¶</a></h1>
<div class="section" id="basic-pyspark-documentation">
<h2>Basic Pyspark documentation<a class="headerlink" href="#basic-pyspark-documentation" title="Permalink to this headline">¶</a></h2>
<div class="topic">
<p class="topic-title first">Introduction</p>
<p>The objective here is to have everything useful for the projects, not to make a complete documentation of the whole package. Here I will try to document both version 1.6 and &gt;2.0. A special enphase will be done on machine learning module ml (mllib is outdated).
We will not review the full Pyspark documentation. For that, look at <a class="reference external" href="http://spark.apache.org/docs/1.6.0/programming-guide.html">http://spark.apache.org/docs/1.6.0/programming-guide.html</a> for version 1.6, <a class="reference external" href="http://spark.apache.org/docs/2.1.0/programming-guide.html">http://spark.apache.org/docs/2.1.0/programming-guide.html</a> for version 2.1.</p>
</div>
<p>To create</p>
<div class="section" id="importing-pyspark-modules">
<h3>Importing Pyspark modules<a class="headerlink" href="#importing-pyspark-modules" title="Permalink to this headline">¶</a></h3>
<p>There are many different ones. among the most commonly used:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
</div>
<div class="section" id="creation-of-pyspark-objects">
<h3>Creation of Pyspark objects<a class="headerlink" href="#creation-of-pyspark-objects" title="Permalink to this headline">¶</a></h3>
<p>First we need to create a Spark context (version 1.6):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkContext</span><span class="p">,</span> <span class="n">SparkConf</span>
<span class="n">appName</span> <span class="o">=</span> <span class="s2">&quot;Your App Name&quot;</span>
<span class="n">master</span> <span class="o">=</span> <span class="s2">&quot;local&quot;</span>
<span class="n">conf</span> <span class="o">=</span> <span class="n">SparkConf</span><span class="p">()</span><span class="o">.</span><span class="n">setAppName</span><span class="p">(</span><span class="n">appName</span><span class="p">)</span><span class="o">.</span><span class="n">setMaster</span><span class="p">(</span><span class="n">master</span><span class="p">)</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">(</span><span class="n">conf</span><span class="o">=</span><span class="n">conf</span><span class="p">)</span>

<span class="c1">#or if you just don&#39;t care (by default, the master will be local)</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">()</span>

<span class="c1">#For closing it (don&#39;t forget, if you want to create a new one later)</span>
<span class="n">sc</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>Using version 2.X, we can use SparkSession:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span> \
  <span class="o">.</span><span class="n">builder</span> \
  <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;Protob Conversion to Parquet&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.some.config.option&quot;</span><span class="p">,</span> <span class="s2">&quot;some-value&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
</pre></div>
</div>
<p>To change the spark configuration (for example to tune the numbers of workers available), we can define it</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#from pyspark import SparkSession,SQLContext #if not present in the notebook (in the &quot;pyspark3Jupyter&quot; command)</span>
<span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span> <span class="c1">#If some default spark running</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span> \
  <span class="o">.</span><span class="n">builder</span> \
  <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;3839_spark&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.executor.cores&quot;</span><span class="p">,</span> <span class="s2">&quot;3&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.executor.memory&quot;</span><span class="p">,</span><span class="s2">&quot;15g&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.dynamicAllocation.maxExecutors&quot;</span><span class="p">,</span><span class="s2">&quot;20&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.dynamicAllocation.cachedExecutorIdleTimeout&quot;</span><span class="p">,</span><span class="s2">&quot;30m&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.sql.parquet.writeLegacyFormat&quot;</span><span class="p">,</span><span class="s2">&quot;true&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">enableHiveSupport</span><span class="p">()</span> \
  <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">sqlCtx</span> <span class="o">=</span> <span class="n">SQLContext</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>
</pre></div>
</div>
<p>If the Spark context is created to read SQL data (i.e. if we have sqlCtx), then we can simply use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sql</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">select * from risk_work.PBAFF_TestTrans</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="c1"># Create a cashed version of data</span>
<span class="n">Data</span> <span class="o">=</span> <span class="n">sqlCtx</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="n">sql</span><span class="p">)</span>
<span class="n">Data</span> <span class="o">=</span> <span class="n">Data</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span> <span class="c1">#this is to cache the object, makes it faster to reload/reuse it later</span>
</pre></div>
</div>
<p>Here a comparison of 2 ways of opening a table:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>
<span class="n">sqlCtx</span> <span class="o">=</span> <span class="n">SQLContext</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>
<span class="n">table1</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;select * from 3839_project_pbaff.trx_201805_mcc_pcat_gir_tra&#39;&#39;&#39;</span><span class="p">)</span>
<span class="n">table2</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="s1">&#39;3839_project_pbaff.trx_201805_mcc_pcat_gir_tra&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="rdds">
<h3>RDDs<a class="headerlink" href="#rdds" title="Permalink to this headline">¶</a></h3>
<p>RDDs are the main data structure type in Pyspark until version 2.X. When possible, let’s work with the Dataframe approach rather than RDDs (they will become more and more deprecated, and are planed to disappear in 3.X)</p>
<p>sc.parallelize allows to convert python list to RDDs</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
<p>Here is the DataCamp Cheatsheet for RDDs:</p>
<div class="figure" id="id2">
<a class="reference internal image-reference" href="Cheatsheets/PySpark_Cheat_Sheet_Python.png"><img alt="map to buried treasure" src="Cheatsheets/PySpark_Cheat_Sheet_Python.png" /></a>
<p class="caption"><span class="caption-text">This Cheatsheet is taken from DataCamp.</span></p>
</div>
</div>
<div class="section" id="dataframes">
<h3>Dataframes<a class="headerlink" href="#dataframes" title="Permalink to this headline">¶</a></h3>
<p>Starting from Pyspark 1.5, Dataframes are built ontop of RDDs and allow to deal easier with data, in a more Pandas-like way. Since version 2.0, they become the main data type.</p>
<p>Here is the DataCamp Cheatsheet for RDDs:</p>
<div class="figure" id="id3">
<a class="reference internal image-reference" href="_images/PySpark_SQL_Cheat_Sheet_Python.png"><img alt="map to buried treasure" src="_images/PySpark_SQL_Cheat_Sheet_Python.png" style="width: 1397.0px; height: 992.0px;" /></a>
<p class="caption"><span class="caption-text">This Cheatsheet is taken from DataCamp.</span></p>
</div>
<p>From Pandas to Pyspark dataframe:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#Loading a Pandas dataframe:</span>
<span class="n">df_pd</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;/home/BC4350/Desktop/Iris.csv&quot;</span><span class="p">)</span>
<span class="c1">#Conversion to a Pyspark dataframe:</span>
<span class="n">df_sp</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">df_pd</span><span class="p">)</span> <span class="c1">#or sc.createDataFrame(df_pd)</span>
<span class="c1">#If needs to go back to Pandas:</span>
<span class="n">df_pd</span> <span class="o">=</span> <span class="n">df_sp</span><span class="o">.</span><span class="n">toPandas</span><span class="p">()</span>
</pre></div>
</div>
<p>From RDD to dataframe:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">toDF</span><span class="p">()</span>
</pre></div>
</div>
<p>Creating a df from scatch: sometimes you have to specify the datatype:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">FloatType</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="n">FloatType</span><span class="p">())</span>

<span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+-----+</span>
<span class="o">|</span><span class="n">value</span><span class="o">|</span>
<span class="o">+-----+</span>
<span class="o">|</span>  <span class="mf">1.0</span><span class="o">|</span>
<span class="o">|</span>  <span class="mf">2.0</span><span class="o">|</span>
<span class="o">|</span>  <span class="mf">3.0</span><span class="o">|</span>
<span class="o">+-----+</span>
</pre></div>
</div>
</div>
<div class="section" id="basic-commands">
<h3>Basic commands<a class="headerlink" href="#basic-commands" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#Counting how many rows in dataframe:</span>
<span class="n">df</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>

<span class="c1">#Displaying first 20 rows:</span>
<span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>

<span class="c1">#Count how many distinct values for a column:</span>
<span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;column&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">distinct</span><span class="p">()</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>

<span class="c1">#Count how many Null in a column:</span>
<span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columName</span><span class="o">.</span><span class="n">isNull</span><span class="p">())</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>

<span class="c1">#Convert the type of a column to float. In fact you can add a new column, columnFloat:</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;columnFloat&quot;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;column&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">))</span>
<span class="c1">#Or simply replace the old column by the new one:</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;column&quot;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;column&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">))</span>

<span class="c1">#Sorting:</span>
<span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="s2">&quot;KNID&quot;</span><span class="p">,</span><span class="s2">&quot;sum(BLPS)&quot;</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>

<span class="c1">#Moving to a Pandas dataframe:</span>
<span class="n">df_pd</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">toPandas</span><span class="p">()</span>

<span class="c1">#Add a new column (dayofmonth) to a dataframe:</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;dayofmonth&#39;</span><span class="p">,</span><span class="n">df</span><span class="o">.</span><span class="n">bgdt</span><span class="p">[</span><span class="mi">7</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">DoubleType</span><span class="p">())</span><span class="o">/</span><span class="mf">31.</span><span class="p">)</span>

<span class="c1">#Add a new column with a constant value:</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">lit</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;NewColumn&#39;</span><span class="p">,</span> <span class="n">lit</span><span class="p">(</span><span class="n">constant</span><span class="p">))</span>

<span class="c1">#Changing the type of a column:</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;pjkd&quot;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;pjkd&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="s2">&quot;int&quot;</span><span class="p">))</span>

<span class="c1">#Renaming a column:</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumnRenamed</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <span class="s1">&#39;value2&#39;</span><span class="p">)</span>

<span class="c1">#Trimming of whitespace in strings</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;columnName&#39;</span><span class="p">,</span> <span class="n">trim</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columnName</span><span class="p">))</span>

<span class="c1">#Filtering (with where clause):</span>
<span class="n">df_filtered</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;init&#39;</span><span class="p">,</span><span class="s1">&#39;initFeatures&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;init&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;0006&#39;</span><span class="p">)</span>

<span class="c1">#Modify only SOME values of a column: we can use a when clause for that:</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;column&#39;</span><span class="p">,</span> <span class="n">when</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;otherColumn&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">something</span><span class="p">,</span> <span class="n">constant</span><span class="p">)</span><span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;column&#39;</span><span class="p">]))</span>

<span class="c1">#Vertical concatenation of 2 dataframes</span>
<span class="n">df_result</span> <span class="o">=</span> <span class="n">df_1</span><span class="o">.</span><span class="n">unionAll</span><span class="p">(</span><span class="n">df_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="aggregating-in-pyspark">
<h3>Aggregating in Pyspark<a class="headerlink" href="#aggregating-in-pyspark" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#Grouping and aggregating:</span>
<span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;KNID&quot;</span><span class="p">,</span><span class="s2">&quot;IDKT&quot;</span><span class="p">,</span><span class="s2">&quot;counter_account&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s2">&quot;BLPS&quot;</span><span class="p">:</span> <span class="s2">&quot;sum&quot;</span><span class="p">,</span> <span class="s2">&quot;KNID&quot;</span><span class="p">:</span> <span class="s2">&quot;count&quot;</span><span class="p">})</span>
<span class="c1">#Other example with aggregation on distinct knid:</span>
<span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s1">&#39;txft&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">func</span><span class="o">.</span><span class="n">countDistinct</span><span class="p">(</span><span class="s1">&#39;knid&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="s1">&#39;count(knid)&#39;</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="bp">False</span><span class="p">)</span>

<span class="c1">#Example: we have a given dataframe like</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)],</span> <span class="p">[</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="s2">&quot;B&quot;</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+---+---+</span>
<span class="o">|</span>  <span class="n">A</span><span class="o">|</span>  <span class="n">B</span><span class="o">|</span>
<span class="o">+---+---+</span>
<span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>  <span class="mi">4</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>  <span class="mi">5</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>  <span class="mi">8</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">3</span><span class="o">|</span>  <span class="mi">6</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">3</span><span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>
<span class="o">+---+---+</span>

<span class="c1">#Then we can build the aggregates for each values of A using:</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>
<span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;A&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">avg</span><span class="p">(</span><span class="s2">&quot;B&quot;</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="s2">&quot;B&quot;</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="s2">&quot;B&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+---+------+------+------+</span>
<span class="o">|</span>  <span class="n">A</span><span class="o">|</span><span class="n">avg</span><span class="p">(</span><span class="n">B</span><span class="p">)</span><span class="o">|</span><span class="nb">min</span><span class="p">(</span><span class="n">B</span><span class="p">)</span><span class="o">|</span><span class="nb">max</span><span class="p">(</span><span class="n">B</span><span class="p">)</span><span class="o">|</span>
<span class="o">+---+------+------+------+</span>
<span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>   <span class="mf">4.0</span><span class="o">|</span>     <span class="mi">4</span><span class="o">|</span>     <span class="mi">4</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">3</span><span class="o">|</span>   <span class="mf">4.0</span><span class="o">|</span>     <span class="mi">2</span><span class="o">|</span>     <span class="mi">6</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>   <span class="mf">6.5</span><span class="o">|</span>     <span class="mi">5</span><span class="o">|</span>     <span class="mi">8</span><span class="o">|</span>
<span class="o">+---+------+------+------+</span>

<span class="c1">#We can also build aggregates using aliases:</span>

<span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;A&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span>
  <span class="n">F</span><span class="o">.</span><span class="n">first</span><span class="p">(</span><span class="s2">&quot;B&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;my first&quot;</span><span class="p">),</span>
  <span class="n">F</span><span class="o">.</span><span class="n">last</span><span class="p">(</span><span class="s2">&quot;B&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;my last&quot;</span><span class="p">),</span>
  <span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s2">&quot;B&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;my everything&quot;</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+---+--------+-------+-------------+</span>
<span class="o">|</span>  <span class="n">A</span><span class="o">|</span><span class="n">my</span> <span class="n">first</span><span class="o">|</span><span class="n">my</span> <span class="n">last</span><span class="o">|</span><span class="n">my</span> <span class="n">everything</span><span class="o">|</span>
<span class="o">+---+--------+-------+-------------+</span>
<span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>       <span class="mi">4</span><span class="o">|</span>      <span class="mi">4</span><span class="o">|</span>            <span class="mi">4</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">3</span><span class="o">|</span>       <span class="mi">6</span><span class="o">|</span>      <span class="mi">2</span><span class="o">|</span>            <span class="mi">8</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>       <span class="mi">8</span><span class="o">|</span>      <span class="mi">5</span><span class="o">|</span>           <span class="mi">13</span><span class="o">|</span>
<span class="o">+---+--------+-------+-------------+</span>
</pre></div>
</div>
</div>
<div class="section" id="joins">
<h3>Joins<a class="headerlink" href="#joins" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://docs.databricks.com/spark/latest/faq/join-two-dataframes-duplicated-column.html">https://docs.databricks.com/spark/latest/faq/join-two-dataframes-duplicated-column.html</a></p>
<p>Here is a simple example of inner join where we keep all left columns and SOME of the right columns:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">df1</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s1">&#39;df1&#39;</span><span class="p">)</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s1">&#39;df2&#39;</span><span class="p">)</span>

<span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df2</span><span class="p">,</span> <span class="n">df1</span><span class="o">.</span><span class="n">id</span> <span class="o">==</span> <span class="n">df2</span><span class="o">.</span><span class="n">id</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;df1.*&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="window-functions">
<h3>Window functions<a class="headerlink" href="#window-functions" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#Let&#39;s say we have the same dataframe as in the aggregation section:</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)],</span> <span class="p">[</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="s2">&quot;B&quot;</span><span class="p">])</span>

<span class="c1">#We can build a window function that computes a diff line by line – ordered or not – given a specific key</span>

<span class="kn">from</span> <span class="nn">pyspark.sql.window</span> <span class="kn">import</span> <span class="n">Window</span>
<span class="n">window_over_A</span> <span class="o">=</span> <span class="n">Window</span><span class="o">.</span><span class="n">partitionBy</span><span class="p">(</span><span class="s2">&quot;A&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="s2">&quot;B&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;diff&quot;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">lead</span><span class="p">(</span><span class="s2">&quot;B&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">window_over_A</span><span class="p">)</span> <span class="o">-</span> <span class="n">df</span><span class="o">.</span><span class="n">B</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+---+---+----+</span>
<span class="o">|</span>  <span class="n">A</span><span class="o">|</span>  <span class="n">B</span><span class="o">|</span><span class="n">diff</span><span class="o">|</span>
<span class="o">+---+---+----+</span>
<span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>  <span class="mi">4</span><span class="o">|</span><span class="n">null</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">3</span><span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>   <span class="mi">4</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">3</span><span class="o">|</span>  <span class="mi">6</span><span class="o">|</span><span class="n">null</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>  <span class="mi">5</span><span class="o">|</span>   <span class="mi">3</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>  <span class="mi">8</span><span class="o">|</span><span class="n">null</span><span class="o">|</span>
<span class="o">+---+---+----+</span>
</pre></div>
</div>
<p>Example: a ranking on a window, and selection of first rank:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">window</span> <span class="o">=</span> <span class="n">Window</span><span class="o">.</span><span class="n">partitionBy</span><span class="p">(</span><span class="s1">&#39;mtts&#39;</span><span class="p">,</span><span class="s1">&#39;pcatkey1&#39;</span><span class="p">,</span><span class="s1">&#39;pcatkey2&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">desc</span><span class="p">(</span><span class="s1">&#39;pcat_opts&#39;</span><span class="p">))</span>
<span class="n">trx_2018</span><span class="o">=</span><span class="n">trx_2018</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;rank_pcatids&quot;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">rank</span><span class="p">()</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">window</span><span class="p">))</span>
<span class="n">trx_2018</span><span class="o">=</span><span class="n">trx_2018</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="s2">&quot;rank_pcatids==1&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="converting-dates-in-pyspark">
<h3>Converting dates in Pyspark<a class="headerlink" href="#converting-dates-in-pyspark" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#Converting date from yyyy mm dd to year, month, day</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">year</span><span class="p">,</span> <span class="n">month</span><span class="p">,</span> <span class="n">dayofmonth</span>
<span class="n">d</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="s1">&#39;20170412&#39;</span><span class="p">}]</span>
<span class="n">dp_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

<span class="n">df_date</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">dp_data</span><span class="p">)</span>
<span class="n">df_date</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+--------+</span>
<span class="o">|</span>    <span class="n">date</span><span class="o">|</span>
<span class="o">+--------+</span>
<span class="o">|</span><span class="mi">20170412</span><span class="o">|</span>
<span class="o">+--------+</span>

<span class="n">df_date</span> <span class="o">=</span> <span class="n">df_date</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">from_unixtime</span><span class="p">(</span><span class="n">unix_timestamp</span><span class="p">(</span><span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;yyyyMMdd&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s1">&#39;date&#39;</span><span class="p">))</span> <span class="c1">#date should first be converted to unixtime</span>
<span class="n">df_date</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;date&quot;</span><span class="p">,</span><span class="n">year</span><span class="p">(</span><span class="s2">&quot;date&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s1">&#39;year&#39;</span><span class="p">),</span> <span class="n">month</span><span class="p">(</span><span class="s2">&quot;date&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s1">&#39;month&#39;</span><span class="p">),</span> <span class="n">dayofmonth</span><span class="p">(</span><span class="s2">&quot;date&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s1">&#39;day&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+-------------------+----+-----+---+</span>
<span class="o">|</span>               <span class="n">date</span><span class="o">|</span><span class="n">year</span><span class="o">|</span><span class="n">month</span><span class="o">|</span><span class="n">day</span><span class="o">|</span>
<span class="o">+-------------------+----+-----+---+</span>
<span class="o">|</span><span class="mi">2017</span><span class="o">-</span><span class="mo">04</span><span class="o">-</span><span class="mi">12</span> <span class="mo">00</span><span class="p">:</span><span class="mo">00</span><span class="p">:</span><span class="mo">00</span><span class="o">|</span><span class="mi">2017</span><span class="o">|</span>    <span class="mi">4</span><span class="o">|</span> <span class="mi">12</span><span class="o">|</span>
<span class="o">+-------------------+----+-----+---+</span>
</pre></div>
</div>
</div>
<div class="section" id="nan-null-none-handling">
<h3>NaN/Null/None handling<a class="headerlink" href="#nan-null-none-handling" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#dropping NaN in whole dataframe:</span>
<span class="n">df</span><span class="o">.</span><span class="n">na</span><span class="o">.</span><span class="n">drop</span><span class="p">()</span>

<span class="c1">#dropping NaN in one column (it will remove all rows of the df where that column contains a NaN):</span>
<span class="c1">#df.select(&quot;column&quot;).na.drop()  this does not work!</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;column&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">isNull</span><span class="p">())</span> <span class="c1">#or df = df.where(df.column.isNull())</span>

<span class="c1">#Filling with NaN or with whatever value, let&#39;s say 50:</span>
<span class="n">df</span><span class="o">.</span><span class="n">na</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>

<span class="c1">#Count how many NaN/Null/None in a column:</span>
<span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columnName</span><span class="o">.</span><span class="n">isNull</span><span class="p">())</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="saving-a-table-in-hadoop">
<h3>Saving a table in Hadoop<a class="headerlink" href="#saving-a-table-in-hadoop" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#mode: one of append, overwrite, error, ignore (default: error)</span>
<span class="c1">#partitionBy: names of partitioning columns</span>
<span class="n">p2</span><span class="o">.</span><span class="n">saveAsTable</span><span class="p">(</span><span class="s1">&#39;risk_work.TULE_savetest&#39;</span><span class="p">,</span><span class="n">partitionBy</span><span class="o">=</span><span class="s1">&#39;KNID&#39;</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;overwrite&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>PySpark does not save the table in an ORC format - therefore, we cannot query the saved tables via Ambari or SQL Developer. So if you want to be able to use these programs to investigate your created tables, you should save the tables like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#Classical saving</span>
<span class="n">df</span><span class="o">.</span><span class="n">saveAsTable</span><span class="p">(</span><span class="s1">&#39;risk_temp.table_name, mode=&#39;</span><span class="n">overwrite</span><span class="s1">&#39;)</span>
<span class="c1">#Specifying the format</span>
<span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;ORC&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">saveAsTable</span><span class="p">(</span><span class="s1">&#39;risk_temp.table_name, mode=&#39;</span><span class="n">overwrite</span><span class="s1">&#39;)</span>
</pre></div>
</div>
</div>
<div class="section" id="filtering-data-in-pyspark">
<h3>Filtering data in Pyspark<a class="headerlink" href="#filtering-data-in-pyspark" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#example 1:</span>
<span class="n">p2</span> <span class="o">=</span> <span class="n">p1</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">p1</span><span class="o">.</span><span class="n">BLPS</span> <span class="o">&gt;</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">#example 2:</span>
<span class="n">p3</span> <span class="o">=</span> <span class="n">p2</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">trim</span><span class="p">(</span><span class="n">p2</span><span class="o">.</span><span class="n">KNID</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;0011106277&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
</pre></div>
</div>
<p>Here is a comparison of the filtering of a dataframe done in Pandas and the same operation done in Pyspark (taken from <a class="reference external" href="https://lab.getbase.com/pandarize-spark-dataframes/">https://lab.getbase.com/pandarize-spark-dataframes/</a>):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#Pandas:</span>
<span class="n">sliced</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">workclass</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="s1">&#39; Local-gov&#39;</span><span class="p">,</span> <span class="s1">&#39; State-gov&#39;</span><span class="p">])</span> \
               <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">education_num</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)][[</span><span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;workclass&#39;</span><span class="p">]]</span>

<span class="n">sliced</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

   <span class="n">age</span>   <span class="n">workclass</span>
<span class="mi">0</span>   <span class="mi">39</span>   <span class="n">State</span><span class="o">-</span><span class="n">gov</span>

<span class="c1">#Pyspark:</span>
<span class="n">slicedSpark</span> <span class="o">=</span> <span class="n">dataSpark</span><span class="p">[</span><span class="n">dataSpark</span><span class="o">.</span><span class="n">workclass</span><span class="o">.</span><span class="n">inSet</span><span class="p">([</span><span class="s1">&#39; Local-gov&#39;</span><span class="p">,</span> <span class="s1">&#39; State-gov&#39;</span><span class="p">])</span>
                         <span class="o">&amp;</span> <span class="p">(</span><span class="n">dataSpark</span><span class="o">.</span><span class="n">education_num</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)][[</span><span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;workclass&#39;</span><span class="p">]]</span>

<span class="n">slicedSpark</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="p">[</span><span class="n">Row</span><span class="p">(</span><span class="n">age</span><span class="o">=</span><span class="mf">48.0</span><span class="p">,</span> <span class="n">workclass</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39; State-gov&#39;</span><span class="p">)]</span>
</pre></div>
</div>
<p>There is one important difference. In Pandas, boolean slicing expects just a boolean series, which means you can apply filter from another DataFrame if they match in length. In Pyspark you can only filter data based on columns from DataFrame you want to filter.</p>
</div>
<div class="section" id="opening-tables-from-data-warehouse-and-mcs">
<h3>Opening tables from Data Warehouse and MCS<a class="headerlink" href="#opening-tables-from-data-warehouse-and-mcs" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="n">TOOLS_PATH</span> <span class="o">=</span> <span class="s1">&#39;/home/BC3589/Git/tools&#39;</span>
<span class="k">if</span> <span class="n">TOOLS_PATH</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="p">:</span>
  <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TOOLS_PATH</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">connection.SQLConnector</span> <span class="kn">import</span> <span class="n">SQLConnector</span>

<span class="c1"># testing connection to Exploration Warehouse</span>
<span class="n">etpew_connector</span> <span class="o">=</span> <span class="n">SQLConnector</span><span class="p">(</span><span class="s1">&#39;ETPEW&#39;</span><span class="p">)</span>
<span class="n">sql</span> <span class="o">=</span> <span class="s2">&quot;select top 1 * from [ETZ3EW].[dbo].[ZW_KUNDE_MST_HV];&quot;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">etpew_connector</span><span class="o">.</span><span class="n">query_to_pandas</span><span class="p">(</span><span class="n">sql</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Loaded from [ETZ3EW].[dbo].[ZW_KUNDE_MST_HV]&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># testing connection to MCS</span>
<span class="n">mcs_connector</span> <span class="o">=</span> <span class="n">SQLConnector</span><span class="p">(</span><span class="s1">&#39;MCS&#39;</span><span class="p">)</span>
<span class="n">sql</span> <span class="o">=</span> <span class="s2">&quot;SELECT top 1 * FROM sys.databases&quot;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">mcs_connector</span><span class="o">.</span><span class="n">query_to_pandas</span><span class="p">(</span><span class="n">sql</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Loaded from sys.databases&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="user-defined-functions-udf">
<h3>User-defined functions (UDF)<a class="headerlink" href="#user-defined-functions-udf" title="Permalink to this headline">¶</a></h3>
<p>Here is an example of removal of whitespaces in a string column of a dataframe:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StringType</span>

<span class="n">spaceDeleteUDF</span> <span class="o">=</span> <span class="n">udf</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">s</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">),</span> <span class="n">StringType</span><span class="p">())</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([(</span><span class="s2">&quot;aaa 111&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;bbb 222&quot;</span><span class="p">,),</span> <span class="p">(</span><span class="s2">&quot;ccc 333&quot;</span><span class="p">,)],</span> <span class="p">[</span><span class="s2">&quot;names&quot;</span><span class="p">])</span>

<span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;names&quot;</span><span class="p">,</span> <span class="n">spaceDeleteUDF</span><span class="p">(</span><span class="s2">&quot;names&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+------+</span>
<span class="o">|</span> <span class="n">names</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">aaa111</span><span class="o">|</span>
<span class="o">|</span><span class="n">bbb222</span><span class="o">|</span>
<span class="o">|</span><span class="n">ccc333</span><span class="o">|</span>
<span class="o">+------+</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="machine-learning-using-the-mllib-package">
<h2>Machine Learning using the MLlib package<a class="headerlink" href="#machine-learning-using-the-mllib-package" title="Permalink to this headline">¶</a></h2>
<p>There are 2 main packages for Machine Learning in Pyspark. MLlib, which is based on RDDs, and ML, which is based on Dataframes. The distinction is very important! After version 2.0, RDDs are deprecated (removed in Spark 3.0) in profit of Pyspark dataframes, which are much more Pandas-friendly.</p>
<div class="section" id="the-random-forest">
<h3>The Random Forest<a class="headerlink" href="#the-random-forest" title="Permalink to this headline">¶</a></h3>
<p>The MLlib’s version of Random Forest is described in details here: <a class="reference external" href="https://spark.apache.org/docs/1.6.1/mllib-ensembles.html">https://spark.apache.org/docs/1.6.1/mllib-ensembles.html</a> .
Here is a very simple working code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.regression</span> <span class="kn">import</span> <span class="n">LabeledPoint</span>
<span class="kn">from</span> <span class="nn">pyspark.mllib.tree</span> <span class="kn">import</span> <span class="n">RandomForest</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Building of some data for supervised ML: first column is label, second is feature</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
  <span class="n">LabeledPoint</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]),</span>
  <span class="n">LabeledPoint</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),</span>
  <span class="n">LabeledPoint</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">]),</span>
  <span class="n">LabeledPoint</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])]</span>

<span class="c1"># Creating RDD from data</span>
<span class="n">trainingData</span><span class="o">=</span><span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">trainingData</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="k">print</span> <span class="n">trainingData</span><span class="o">.</span><span class="n">toDF</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+---------+-----+</span>
<span class="o">|</span> <span class="n">features</span><span class="o">|</span><span class="n">label</span><span class="o">|</span>
<span class="o">+---------+-----+</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">]</span><span class="o">|</span>  <span class="mf">0.0</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">]</span><span class="o">|</span>  <span class="mf">0.0</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">]</span><span class="o">|</span>  <span class="mf">1.0</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">]</span><span class="o">|</span>  <span class="mf">1.0</span><span class="o">|</span>
<span class="o">+---------+-----+</span>

<span class="c1"># Model creation</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RandomForest</span><span class="o">.</span><span class="n">trainClassifier</span><span class="p">(</span><span class="n">trainingData</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">{},</span> <span class="mi">3</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="k">print</span> <span class="n">model</span><span class="o">.</span><span class="n">numTrees</span><span class="p">()</span>
<span class="k">print</span> <span class="n">model</span><span class="o">.</span><span class="n">totalNumNodes</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">toDebugString</span><span class="p">())</span>

<span class="c1"># Predicting a new sample</span>
<span class="n">rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([[</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">]])</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">rdd</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
<p>Here is another working example, on the IRIS dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.regression</span> <span class="kn">import</span> <span class="n">LabeledPoint</span>
<span class="kn">from</span> <span class="nn">pyspark.mllib.tree</span> <span class="kn">import</span> <span class="n">RandomForest</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">Convert_to_LabelPoint_format</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
  <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">  This function is intended for the preparation of Supervised ML input data, using the MLlib package of Pyspark.</span>
<span class="sd">  Input:</span>
<span class="sd">  - X: a numpy array containing the features (as many columns as features)</span>
<span class="sd">  - y: a numpy array containing the labels (1 column)</span>
<span class="sd">  Output:</span>
<span class="sd">  - data: a python list containing the data in LabeledPoint format</span>
<span class="sd">  &#39;&#39;&#39;</span>
  <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)):</span>
      <span class="n">X_list</span> <span class="o">=</span>  <span class="nb">list</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,:])</span>
      <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">LabeledPoint</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">X_list</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">data</span>

<span class="c1">#USING IRIS DATASET:</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">idx</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)))</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>              <span class="c1">#We shuffle it (important if we want to split in train and test sets)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">Convert_to_LabelPoint_format</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Creating RDD from data</span>
<span class="n">data_rdd</span><span class="o">=</span><span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">data_rdd</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="k">print</span> <span class="n">data_rdd</span><span class="o">.</span><span class="n">toDF</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="o">+-----------------+-----+</span>
<span class="o">|</span>         <span class="n">features</span><span class="o">|</span><span class="n">label</span><span class="o">|</span>
<span class="o">+-----------------+-----+</span>
<span class="o">|</span><span class="p">[</span><span class="mf">5.1</span><span class="p">,</span><span class="mf">3.4</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">0.2</span><span class="p">]</span><span class="o">|</span>  <span class="mf">0.0</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">6.7</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">5.2</span><span class="p">,</span><span class="mf">2.3</span><span class="p">]</span><span class="o">|</span>  <span class="mf">2.0</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">5.0</span><span class="p">,</span><span class="mf">3.6</span><span class="p">,</span><span class="mf">1.4</span><span class="p">,</span><span class="mf">0.2</span><span class="p">]</span><span class="o">|</span>  <span class="mf">0.0</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">6.8</span><span class="p">,</span><span class="mf">3.2</span><span class="p">,</span><span class="mf">5.9</span><span class="p">,</span><span class="mf">2.3</span><span class="p">]</span><span class="o">|</span>  <span class="mf">2.0</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">6.1</span><span class="p">,</span><span class="mf">2.9</span><span class="p">,</span><span class="mf">4.7</span><span class="p">,</span><span class="mf">1.4</span><span class="p">]</span><span class="o">|</span>  <span class="mf">1.0</span><span class="o">|</span>
<span class="o">+-----------------+-----+</span>

<span class="c1">#Splitting the data in training and testing set</span>
<span class="p">(</span><span class="n">trainingData</span><span class="p">,</span> <span class="n">testData</span><span class="p">)</span> <span class="o">=</span> <span class="n">data_rdd</span><span class="o">.</span><span class="n">randomSplit</span><span class="p">([</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span>

<span class="c1"># Model creation</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RandomForest</span><span class="o">.</span><span class="n">trainClassifier</span><span class="p">(</span><span class="n">trainingData</span><span class="p">,</span> <span class="n">numClasses</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">categoricalFeaturesInfo</span><span class="o">=</span><span class="p">{},</span>
                                   <span class="n">numTrees</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">featureSubsetStrategy</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
                                   <span class="n">impurity</span><span class="o">=</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="n">maxDepth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">maxBins</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="k">print</span> <span class="n">model</span><span class="o">.</span><span class="n">numTrees</span><span class="p">()</span>
<span class="k">print</span> <span class="n">model</span><span class="o">.</span><span class="n">totalNumNodes</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">toDebugString</span><span class="p">())</span>
<span class="k">print</span>

<span class="c1"># Predicting for test data</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testData</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">features</span><span class="p">))</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

<span class="c1">#ACCURACY</span>
<span class="n">testData_pd</span> <span class="o">=</span> <span class="n">testData</span><span class="o">.</span><span class="n">toDF</span><span class="p">()</span><span class="o">.</span><span class="n">toPandas</span><span class="p">()</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">testData_pd</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span>
<span class="n">accuracy</span>    <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Accuracy = &quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>
</div>
<p>(‘Accuracy = ‘, 0.9772)</p>
</div>
<div class="section" id="kernel-density-estimation-here-1-d-only">
<h3>Kernel Density Estimation (here 1-D only)<a class="headerlink" href="#kernel-density-estimation-here-1-d-only" title="Permalink to this headline">¶</a></h3>
<p>Here we still use the old mllib package. Look for the same using the ml one.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.stat</span> <span class="kn">import</span> <span class="n">KernelDensity</span>
<span class="kn">from</span> <span class="nn">pyspark.mllib.random</span> <span class="kn">import</span> <span class="n">RandomRDDs</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="c1"># Create the estimator</span>
<span class="n">kd</span> <span class="o">=</span> <span class="n">KernelDensity</span><span class="p">()</span>
<span class="c1"># Choose the range to evaluate density on</span>
<span class="n">ran</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mf">0.1</span><span class="p">);</span>
<span class="c1"># Set kernel bandwidth</span>
<span class="n">kd</span><span class="o">.</span><span class="n">setBandwidth</span><span class="p">(</span><span class="mf">3.0</span><span class="p">)</span>

<span class="c1">#Here with a random normal sample</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">RandomRDDs</span><span class="o">.</span><span class="n">normalRDD</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">kd</span><span class="o">.</span><span class="n">setSample</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
<span class="c1">#plot of the histogram</span>
<span class="n">num_bins</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">patches</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">collect</span><span class="p">(),</span> <span class="n">num_bins</span><span class="p">,</span> <span class="n">normed</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1">#plot of the kde</span>
<span class="n">densities</span> <span class="o">=</span> <span class="n">kd</span><span class="o">.</span><span class="n">estimate</span><span class="p">(</span><span class="n">ran</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ran</span><span class="p">,</span><span class="n">densities</span><span class="p">)</span>

<span class="c1">#Here with a true variable: the age (takes some time to compile)</span>
<span class="n">sql</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">select * from risk_temp.TULE_TP5</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="n">p1</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="n">sql</span><span class="p">)</span>
<span class="n">p2</span> <span class="o">=</span> <span class="n">p1</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">p1</span><span class="o">.</span><span class="n">statusondate</span> <span class="o">==</span> <span class="s1">&#39;2014-01-01&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
<span class="n">p_age</span> <span class="o">=</span> <span class="n">p2</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">y</span><span class="p">:</span> <span class="n">y</span><span class="p">[</span><span class="s1">&#39;ac_age_cust_01&#39;</span><span class="p">])</span>
<span class="n">kd</span><span class="o">.</span><span class="n">setSample</span><span class="p">(</span><span class="n">p_age</span><span class="p">)</span>
<span class="c1"># Choose the range to evaluate density on</span>
<span class="n">ran</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mf">0.1</span><span class="p">);</span>  <span class="c1">#We evaluate the KDE in the age range [0,100]</span>
<span class="n">densities</span> <span class="o">=</span> <span class="n">kd</span><span class="o">.</span><span class="n">estimate</span><span class="p">(</span><span class="n">ran</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ran</span><span class="p">,</span><span class="n">densities</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="machine-learning-using-the-ml-package">
<h2>Machine Learning using the ML package<a class="headerlink" href="#machine-learning-using-the-ml-package" title="Permalink to this headline">¶</a></h2>
<p>For the machine-learning package, look at:</p>
<ul class="simple">
<li>Version 1.6: <a class="reference external" href="https://spark.apache.org/docs/1.6.0/ml-guide.html">https://spark.apache.org/docs/1.6.0/ml-guide.html</a></li>
<li>Version 2.1: <a class="reference external" href="https://spark.apache.org/docs/2.1.0/ml-guide.html">https://spark.apache.org/docs/2.1.0/ml-guide.html</a></li>
</ul>
<div class="section" id="convert-a-string-column-to-indexed-labels">
<h3>Convert a string column to indexed labels<a class="headerlink" href="#convert-a-string-column-to-indexed-labels" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">StringIndexer</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
  <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">)],</span>
  <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;category&quot;</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+---+--------+</span>
<span class="o">|</span> <span class="nb">id</span><span class="o">|</span><span class="n">category</span><span class="o">|</span>
<span class="o">+---+--------+</span>
<span class="o">|</span>  <span class="mi">0</span><span class="o">|</span>       <span class="n">a</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>       <span class="n">b</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>       <span class="n">c</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">3</span><span class="o">|</span>       <span class="n">a</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">4</span><span class="o">|</span>       <span class="n">a</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">5</span><span class="o">|</span>       <span class="n">c</span><span class="o">|</span>
<span class="o">+---+--------+</span>

<span class="n">indexer</span> <span class="o">=</span> <span class="n">StringIndexer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;category&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;categoryIndex&quot;</span><span class="p">)</span>
<span class="n">indexed</span> <span class="o">=</span> <span class="n">indexer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">indexed</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+---+--------+-------------+</span>
<span class="o">|</span> <span class="nb">id</span><span class="o">|</span><span class="n">category</span><span class="o">|</span><span class="n">categoryIndex</span><span class="o">|</span>
<span class="o">+---+--------+-------------+</span>
<span class="o">|</span>  <span class="mi">0</span><span class="o">|</span>       <span class="n">a</span><span class="o">|</span>          <span class="mf">0.0</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>       <span class="n">b</span><span class="o">|</span>          <span class="mf">2.0</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>       <span class="n">c</span><span class="o">|</span>          <span class="mf">1.0</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">3</span><span class="o">|</span>       <span class="n">a</span><span class="o">|</span>          <span class="mf">0.0</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">4</span><span class="o">|</span>       <span class="n">a</span><span class="o">|</span>          <span class="mf">0.0</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">5</span><span class="o">|</span>       <span class="n">c</span><span class="o">|</span>          <span class="mf">1.0</span><span class="o">|</span>
<span class="o">+---+--------+-------------+</span>
</pre></div>
</div>
</div>
<div class="section" id="assembling-multiple-columns-in-one-features-columns-using-vectorassembler">
<h3>Assembling multiple columns in one “features” columns using VectorAssembler<a class="headerlink" href="#assembling-multiple-columns-in-one-features-columns-using-vectorassembler" title="Permalink to this headline">¶</a></h3>
<p>VectorAssembler is a transformer that combines a given list of columns into a single vector column. It is useful for supervised ML tools like Random Forest.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">VectorAssembler</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
  <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]),</span> <span class="mf">1.0</span><span class="p">)],</span>
  <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;mobile&quot;</span><span class="p">,</span> <span class="s2">&quot;userFeatures&quot;</span><span class="p">,</span> <span class="s2">&quot;clicked&quot;</span><span class="p">])</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+---+----+------+--------------+-------+</span>
<span class="o">|</span> <span class="nb">id</span><span class="o">|</span><span class="n">hour</span><span class="o">|</span><span class="n">mobile</span><span class="o">|</span>  <span class="n">userFeatures</span><span class="o">|</span><span class="n">clicked</span><span class="o">|</span>
<span class="o">+---+----+------+--------------+-------+</span>
<span class="o">|</span>  <span class="mi">0</span><span class="o">|</span>  <span class="mi">18</span><span class="o">|</span>   <span class="mf">1.0</span><span class="o">|</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">]</span><span class="o">|</span>    <span class="mf">1.0</span><span class="o">|</span>
<span class="o">+---+----+------+--------------+-------+</span>

<span class="n">assembler</span> <span class="o">=</span> <span class="n">VectorAssembler</span><span class="p">(</span>
  <span class="n">inputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;mobile&quot;</span><span class="p">,</span> <span class="s2">&quot;userFeatures&quot;</span><span class="p">],</span>
  <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">assembler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+---+----+------+--------------+-------+-----------------------+</span>
<span class="o">|</span> <span class="nb">id</span><span class="o">|</span><span class="n">hour</span><span class="o">|</span><span class="n">mobile</span><span class="o">|</span>  <span class="n">userFeatures</span><span class="o">|</span><span class="n">clicked</span><span class="o">|</span>               <span class="n">features</span><span class="o">|</span>
<span class="o">+---+----+------+--------------+-------+-----------------------+</span>
<span class="o">|</span>  <span class="mi">0</span><span class="o">|</span>  <span class="mi">18</span><span class="o">|</span>   <span class="mf">1.0</span><span class="o">|</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">]</span><span class="o">|</span>    <span class="mf">1.0</span><span class="o">|</span><span class="p">[</span><span class="mf">18.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">]</span><span class="o">|</span>
<span class="o">+---+----+------+--------------+-------+-----------------------+</span>
</pre></div>
</div>
</div>
<div class="section" id="one-hot-encoding">
<h3>One-Hot encoding<a class="headerlink" href="#one-hot-encoding" title="Permalink to this headline">¶</a></h3>
<p>One-hot encoding (<a class="reference external" href="https://en.wikipedia.org/wiki/One-hot">https://en.wikipedia.org/wiki/One-hot</a>) maps a column of label indices to a column of binary vectors, with at most a single one-value. See also <a class="reference external" href="https://spark.apache.org/docs/2.1.0/ml-features.html#onehotencoder">https://spark.apache.org/docs/2.1.0/ml-features.html#onehotencoder</a>
In this example, we have a dataframe with 5 different values (a-f) and we one-hot encode that column. It is a two-steps task: first need to string-index it, then encode it.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">StringIndexer</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
  <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="s2">&quot;e&quot;</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="s2">&quot;e&quot;</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="s2">&quot;f&quot;</span><span class="p">),</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;category&quot;</span><span class="p">])</span>

<span class="n">stringIndexer</span> <span class="o">=</span> <span class="n">StringIndexer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;category&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;categoryIndex&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">stringIndexer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">indexed</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;categoryIndex&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;categoryVec&quot;</span><span class="p">)</span>
<span class="n">encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">indexed</span><span class="p">)</span>
<span class="n">encoded</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+---+--------+-------------+-------------+</span>
<span class="o">|</span> <span class="nb">id</span><span class="o">|</span><span class="n">category</span><span class="o">|</span><span class="n">categoryIndex</span><span class="o">|</span>  <span class="n">categoryVec</span><span class="o">|</span>
<span class="o">+---+--------+-------------+-------------+</span>
<span class="o">|</span>  <span class="mi">0</span><span class="o">|</span>       <span class="n">a</span><span class="o">|</span>          <span class="mf">0.0</span><span class="o">|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">0</span><span class="p">],[</span><span class="mf">1.0</span><span class="p">])</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>       <span class="n">b</span><span class="o">|</span>          <span class="mf">2.0</span><span class="o">|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">2</span><span class="p">],[</span><span class="mf">1.0</span><span class="p">])</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>       <span class="n">c</span><span class="o">|</span>          <span class="mf">3.0</span><span class="o">|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">3</span><span class="p">],[</span><span class="mf">1.0</span><span class="p">])</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">3</span><span class="o">|</span>       <span class="n">a</span><span class="o">|</span>          <span class="mf">0.0</span><span class="o">|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">0</span><span class="p">],[</span><span class="mf">1.0</span><span class="p">])</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">4</span><span class="o">|</span>       <span class="n">a</span><span class="o">|</span>          <span class="mf">0.0</span><span class="o">|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">0</span><span class="p">],[</span><span class="mf">1.0</span><span class="p">])</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">5</span><span class="o">|</span>       <span class="n">c</span><span class="o">|</span>          <span class="mf">3.0</span><span class="o">|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">3</span><span class="p">],[</span><span class="mf">1.0</span><span class="p">])</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">6</span><span class="o">|</span>       <span class="n">b</span><span class="o">|</span>          <span class="mf">2.0</span><span class="o">|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">2</span><span class="p">],[</span><span class="mf">1.0</span><span class="p">])</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">7</span><span class="o">|</span>       <span class="n">d</span><span class="o">|</span>          <span class="mf">4.0</span><span class="o">|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">4</span><span class="p">],[</span><span class="mf">1.0</span><span class="p">])</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">8</span><span class="o">|</span>       <span class="n">d</span><span class="o">|</span>          <span class="mf">4.0</span><span class="o">|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">4</span><span class="p">],[</span><span class="mf">1.0</span><span class="p">])</span><span class="o">|</span>
<span class="o">|</span>  <span class="mi">9</span><span class="o">|</span>       <span class="n">e</span><span class="o">|</span>          <span class="mf">1.0</span><span class="o">|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">1</span><span class="p">],[</span><span class="mf">1.0</span><span class="p">])</span><span class="o">|</span>
<span class="o">|</span> <span class="mi">10</span><span class="o">|</span>       <span class="n">e</span><span class="o">|</span>          <span class="mf">1.0</span><span class="o">|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">1</span><span class="p">],[</span><span class="mf">1.0</span><span class="p">])</span><span class="o">|</span>
<span class="o">|</span> <span class="mi">11</span><span class="o">|</span>       <span class="n">f</span><span class="o">|</span>          <span class="mf">5.0</span><span class="o">|</span>    <span class="p">(</span><span class="mi">5</span><span class="p">,[],[])</span><span class="o">|</span>
<span class="o">+---+--------+-------------+-------------+</span>
</pre></div>
</div>
</div>
<div class="section" id="grouping-data-using-bucketizer">
<h3>Grouping data using Bucketizer<a class="headerlink" href="#grouping-data-using-bucketizer" title="Permalink to this headline">¶</a></h3>
<p>Bucketizer is a transformer that groups a given column using splits defined by the user. In this example, we group a few days of the month in 3 groups: [1-10], [11-20], [21-31]</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">Bucketizer</span>

<span class="c1">#Let&#39;s create a sample with some days of the month</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,),</span> <span class="p">(</span><span class="mi">11</span><span class="p">,),</span> <span class="p">(</span><span class="mi">20</span><span class="p">,),</span> <span class="p">(</span><span class="mi">27</span><span class="p">,),</span> <span class="p">(</span><span class="mi">31</span><span class="p">,)]</span>
<span class="n">dataFrame</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;day&quot;</span><span class="p">])</span>
<span class="n">dataFrame</span> <span class="o">=</span> <span class="n">dataFrame</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;day&quot;</span><span class="p">,</span> <span class="n">dataFrame</span><span class="p">[</span><span class="s2">&quot;day&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="s2">&quot;double&quot;</span><span class="p">))</span> <span class="c1">#we need to transform them in double</span>

<span class="c1">#We want to groupe these days in 3 groups [1-10], [11-20], [21-31]</span>
<span class="n">splits</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">31</span><span class="p">]</span>
<span class="n">bucketizer</span> <span class="o">=</span> <span class="n">Bucketizer</span><span class="p">(</span><span class="n">splits</span><span class="o">=</span><span class="n">splits</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;day&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;dayGrouped&quot;</span><span class="p">)</span>

<span class="c1"># Transform original data into its bucket index.</span>
<span class="n">bucketedData</span> <span class="o">=</span> <span class="n">bucketizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Bucketizer output with </span><span class="si">%d</span><span class="s2"> buckets&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">bucketizer</span><span class="o">.</span><span class="n">getSplits</span><span class="p">())</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">bucketedData</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1">#Bucketizer output with 3 buckets</span>
<span class="o">+----+----------+</span>
<span class="o">|</span> <span class="n">day</span><span class="o">|</span><span class="n">dayGrouped</span><span class="o">|</span>
<span class="o">+----+----------+</span>
<span class="o">|</span> <span class="mf">1.0</span><span class="o">|</span>       <span class="mf">0.0</span><span class="o">|</span>
<span class="o">|</span> <span class="mf">7.0</span><span class="o">|</span>       <span class="mf">0.0</span><span class="o">|</span>
<span class="o">|</span><span class="mf">11.0</span><span class="o">|</span>       <span class="mf">1.0</span><span class="o">|</span>
<span class="o">|</span><span class="mf">20.0</span><span class="o">|</span>       <span class="mf">1.0</span><span class="o">|</span>
<span class="o">|</span><span class="mf">27.0</span><span class="o">|</span>       <span class="mf">2.0</span><span class="o">|</span>
<span class="o">|</span><span class="mf">31.0</span><span class="o">|</span>       <span class="mf">2.0</span><span class="o">|</span>
<span class="o">+----+----------+</span>
</pre></div>
</div>
</div>
<div class="section" id="id1">
<h3>The Random Forest<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>Here is a working example of the Random Forest using the ML package, applied on the IRIS dataset (so, Multi-class target!):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.classification</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">VectorAssembler</span><span class="p">,</span> <span class="n">StringIndexer</span><span class="p">,</span> <span class="n">VectorIndexer</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.evaluation</span> <span class="kn">import</span> <span class="n">MulticlassClassificationEvaluator</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="c1">#USING IRIS DATASET:</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>                       <span class="c1">#The Iris dataset is available through the scikit-learn API</span>
<span class="n">idx</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)))</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>              <span class="c1">#We shuffle it (important if we want to split in train and test sets)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="c1"># Load data in Pandas dataFrame and then in a Pyspark dataframe</span>
<span class="n">data_pd</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;sepal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal_width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal_width&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">data_df</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data_pd</span><span class="p">)</span>

<span class="c1"># This transforms the labels into indexes. See https://spark.apache.org/docs/latest/ml-features.html#stringindexer</span>
<span class="n">labelIndexer</span> <span class="o">=</span> <span class="n">StringIndexer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;indexedLabel&quot;</span><span class="p">)</span>

<span class="c1"># This groups all the features in one pack &quot;features&quot;, needed for the VectorIndexer</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">VectorAssembler</span><span class="p">(</span><span class="n">inputCols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sepal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal_width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal_width&#39;</span><span class="p">],</span><span class="n">outputCol</span> <span class="o">=</span> <span class="s2">&quot;features&quot;</span><span class="p">)</span>

<span class="c1"># This identifies categorical features, and indexes them. Set maxCategories so features with &gt; 4 distinct values are treated as continuous. #https://spark.apache.org/docs/latest/ml-features.html#stringindexer</span>
<span class="n">featureIndexer</span> <span class="o">=</span> <span class="n">VectorIndexer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;indexedFeatures&quot;</span><span class="p">,</span> <span class="n">maxCategories</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># Split the data into training and test sets (30% held out for testing)</span>
<span class="p">(</span><span class="n">trainingData</span><span class="p">,</span> <span class="n">testData</span><span class="p">)</span> <span class="o">=</span> <span class="n">data_df</span><span class="o">.</span><span class="n">randomSplit</span><span class="p">([</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span>

<span class="c1"># Train a RandomForest model.</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">labelCol</span><span class="o">=</span><span class="s2">&quot;indexedLabel&quot;</span><span class="p">,</span> <span class="n">featuresCol</span><span class="o">=</span><span class="s2">&quot;indexedFeatures&quot;</span><span class="p">,</span> <span class="n">numTrees</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>  <span class="n">maxDepth</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Chain indexers and forest in a Pipeline</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">labelIndexer</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">,</span> <span class="n">featureIndexer</span><span class="p">,</span> <span class="n">rf</span><span class="p">])</span>

<span class="c1"># Train model.  This also runs the indexers.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>

<span class="c1"># Make predictions.</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">testData</span><span class="p">)</span>

<span class="c1"># Select example rows to display.</span>
<span class="n">predictions</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;prediction&quot;</span><span class="p">,</span> <span class="s2">&quot;indexedLabel&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Select (prediction, true label) and compute test error</span>
<span class="n">evaluator</span> <span class="o">=</span> <span class="n">MulticlassClassificationEvaluator</span><span class="p">(</span><span class="n">labelCol</span><span class="o">=</span><span class="s2">&quot;indexedLabel&quot;</span><span class="p">,</span> <span class="n">predictionCol</span><span class="o">=</span><span class="s2">&quot;prediction&quot;</span><span class="p">,</span> <span class="n">metricName</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Accuracy = </span><span class="si">%g</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>
</pre></div>
</div>
<p>Accuracy = 0.973684.</p>
</div>
<div class="section" id="evaluation-of-accuracy">
<h3>Evaluation of accuracy<a class="headerlink" href="#evaluation-of-accuracy" title="Permalink to this headline">¶</a></h3>
<p>For binary (2-classes) target, we can use the area under the ROC curve (AUC):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.evaluation</span> <span class="kn">import</span> <span class="n">BinaryClassificationEvaluator</span>
<span class="n">scoreAndLabels</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]]),</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="p">[(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)])</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">scoreAndLabels</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;raw&quot;</span><span class="p">,</span> <span class="s2">&quot;trueLabel&quot;</span><span class="p">])</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+---------+---------+</span>
<span class="o">|</span>      <span class="n">raw</span><span class="o">|</span><span class="n">trueLabel</span><span class="o">|</span>   <span class="c1">#left column contains probabilities, right contains the true label (not the derived ones)</span>
<span class="o">+---------+---------+</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.9</span><span class="p">,</span><span class="mf">0.1</span><span class="p">]</span><span class="o">|</span>      <span class="mf">0.0</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.9</span><span class="p">,</span><span class="mf">0.1</span><span class="p">]</span><span class="o">|</span>      <span class="mf">1.0</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.6</span><span class="p">,</span><span class="mf">0.4</span><span class="p">]</span><span class="o">|</span>      <span class="mf">0.0</span><span class="o">|</span>
<span class="o">+---------+---------+</span>

<span class="n">evaluator</span> <span class="o">=</span> <span class="n">BinaryClassificationEvaluator</span><span class="p">(</span><span class="n">rawPredictionCol</span><span class="o">=</span><span class="s2">&quot;raw&quot;</span><span class="p">,</span> <span class="n">labelCol</span><span class="o">=</span><span class="s2">&quot;trueLabel&quot;</span><span class="p">,</span> <span class="n">metricName</span><span class="o">=</span><span class="s2">&quot;areaUnderROC&quot;</span><span class="p">)</span>
<span class="k">print</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="mf">0.708</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="text-analysis-in-pyspark">
<h2>Text analysis in Pyspark<a class="headerlink" href="#text-analysis-in-pyspark" title="Permalink to this headline">¶</a></h2>
<div class="section" id="dealing-with-text-tokenizer-hashing-idf">
<h3>Dealing with text: Tokenizer, Hashing, IDF<a class="headerlink" href="#dealing-with-text-tokenizer-hashing-idf" title="Permalink to this headline">¶</a></h3>
<p>Here from Tue code 1 model in a day, in short</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Split text field in words</span>
<span class="n">tokenizer</span>        <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;txft_70&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">)</span>
<span class="n">wordsData</span>      <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Data</span><span class="p">)</span>

<span class="c1"># Create Hash table data</span>
<span class="n">NHash</span>          <span class="o">=</span> <span class="mi">256</span> <span class="c1"># number of hashing values used to describe the text</span>
<span class="n">hashing</span>        <span class="o">=</span> <span class="n">HashingTF</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;rawTextFeatures&quot;</span><span class="p">,</span> <span class="n">numFeatures</span><span class="o">=</span><span class="n">NHash</span><span class="p">)</span>
<span class="n">featurizedData</span> <span class="o">=</span> <span class="n">hashing</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">wordsData</span><span class="p">)</span>

<span class="c1"># Calculate inverse document frequency</span>
<span class="n">idf</span>            <span class="o">=</span> <span class="n">IDF</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;rawTextFeatures&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;textFeatures&quot;</span><span class="p">)</span>
<span class="n">idfModel</span>       <span class="o">=</span> <span class="n">idf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">featurizedData</span><span class="p">)</span>
<span class="n">DataText</span>       <span class="o">=</span> <span class="n">idfModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">featurizedData</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
</pre></div>
</div>
<p>Here a more elaborated example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">HashingTF</span><span class="p">,</span> <span class="n">IDF</span><span class="p">,</span> <span class="n">Tokenizer</span>

<span class="n">sentenceData</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
  <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Hi I heard about Spark&quot;</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;I wish Java could use case classes&quot;</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Logistic regression models are neat&quot;</span><span class="p">)],</span> <span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="s2">&quot;sentence&quot;</span><span class="p">])</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;sentence&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">)</span> <span class="c1">#https://spark.apache.org/docs/2.1.0/ml-features.html#tokenizer</span>
<span class="n">wordsData</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">sentenceData</span><span class="p">)</span>
<span class="n">hashingTF</span> <span class="o">=</span> <span class="n">HashingTF</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;rawFeatures&quot;</span><span class="p">,</span> <span class="n">numFeatures</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> <span class="c1">#https://spark.apache.org/docs/2.1.0/ml-features.html#tf-idf</span>
<span class="n">featurizedData</span> <span class="o">=</span> <span class="n">hashingTF</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">wordsData</span><span class="p">)</span>
<span class="n">featurizedData</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+-----+--------------------+--------------------+--------------------+</span>
<span class="o">|</span><span class="n">label</span><span class="o">|</span>            <span class="n">sentence</span><span class="o">|</span>               <span class="n">words</span><span class="o">|</span>         <span class="n">rawFeatures</span><span class="o">|</span>
<span class="o">+-----+--------------------+--------------------+--------------------+</span>
<span class="o">|</span>    <span class="mi">0</span><span class="o">|</span><span class="n">Hi</span> <span class="n">I</span> <span class="n">heard</span> <span class="n">about</span> <span class="o">...|</span><span class="p">[</span><span class="n">hi</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">heard</span><span class="p">,</span> <span class="n">ab</span><span class="o">...|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">2.</span><span class="o">..|</span>
<span class="o">|</span>    <span class="mi">0</span><span class="o">|</span><span class="n">I</span> <span class="n">wish</span> <span class="n">Java</span> <span class="n">could</span><span class="o">...|</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">wish</span><span class="p">,</span> <span class="n">java</span><span class="p">,</span> <span class="n">c</span><span class="o">...|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mf">1.0</span><span class="o">...|</span>
<span class="o">|</span>    <span class="mi">1</span><span class="o">|</span><span class="n">Logistic</span> <span class="n">regressi</span><span class="o">...|</span><span class="p">[</span><span class="n">logistic</span><span class="p">,</span> <span class="n">regres</span><span class="o">...|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mf">1.0</span><span class="o">...|</span>
<span class="o">+-----+--------------------+--------------------+--------------------+</span>

<span class="n">idf</span> <span class="o">=</span> <span class="n">IDF</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;rawFeatures&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">)</span>
<span class="n">idfModel</span> <span class="o">=</span> <span class="n">idf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">featurizedData</span><span class="p">)</span>
<span class="n">rescaledData</span> <span class="o">=</span> <span class="n">idfModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">featurizedData</span><span class="p">)</span>
<span class="k">for</span> <span class="n">features_label</span> <span class="ow">in</span> <span class="n">rescaledData</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
  <span class="k">print</span><span class="p">(</span><span class="n">features_label</span><span class="p">)</span>

<span class="c1">#Row(features=SparseVector(5, {0: 0.0, 2: 0.5754, 4: 0.0}), label=0)</span>
<span class="c1">#Row(features=SparseVector(5, {0: 0.0, 2: 0.5754, 3: 0.2877, 4: 0.0}), label=0)</span>
<span class="c1">#Row(features=SparseVector(5, {0: 0.0, 1: 0.6931, 3: 0.5754, 4: 0.0}), label=1)</span>

<span class="n">rescaledData</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+-----+--------------------+--------------------+--------------------+--------------------+</span>
<span class="o">|</span><span class="n">label</span><span class="o">|</span>            <span class="n">sentence</span><span class="o">|</span>               <span class="n">words</span><span class="o">|</span>         <span class="n">rawFeatures</span><span class="o">|</span>            <span class="n">features</span><span class="o">|</span>
<span class="o">+-----+--------------------+--------------------+--------------------+--------------------+</span>
<span class="o">|</span>    <span class="mi">0</span><span class="o">|</span><span class="n">Hi</span> <span class="n">I</span> <span class="n">heard</span> <span class="n">about</span> <span class="o">...|</span><span class="p">[</span><span class="n">hi</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">heard</span><span class="p">,</span> <span class="n">ab</span><span class="o">...|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">2.</span><span class="o">..|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.</span><span class="o">..|</span>
<span class="o">|</span>    <span class="mi">0</span><span class="o">|</span><span class="n">I</span> <span class="n">wish</span> <span class="n">Java</span> <span class="n">could</span><span class="o">...|</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">wish</span><span class="p">,</span> <span class="n">java</span><span class="p">,</span> <span class="n">c</span><span class="o">...|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mf">1.0</span><span class="o">...|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mf">0.0</span><span class="o">...|</span>
<span class="o">|</span>    <span class="mi">1</span><span class="o">|</span><span class="n">Logistic</span> <span class="n">regressi</span><span class="o">...|</span><span class="p">[</span><span class="n">logistic</span><span class="p">,</span> <span class="n">regres</span><span class="o">...|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mf">1.0</span><span class="o">...|</span><span class="p">(</span><span class="mi">5</span><span class="p">,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mf">0.0</span><span class="o">...|</span>
<span class="o">+-----+--------------------+--------------------+--------------------+--------------------+</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Text_Mining_Documentation.html" class="btn btn-neutral float-right" title="Text Mining in Python" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Sklearn_Documentation.html" class="btn btn-neutral" title="Scikit-learn" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, pmeu.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>